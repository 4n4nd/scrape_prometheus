apiVersion: v1
kind: Template
metadata:
  name: scrape-prometheus-cronjob

objects:
- apiVersion: v1
  kind: ImageStream
  metadata:
    name: ${APPLICATION_NAME}
    labels:
      app: ${APPLICATION_NAME}
  spec:
    dockerImageRepository: ${APPLICATION_NAME}
    tags:
    - name: latest
    lookupPolicy:
      local: true


- apiVersion: v1
  kind: BuildConfig
  metadata:
    name: ${APPLICATION_NAME}
    labels:
      app: ${APPLICATION_NAME}
  spec:
    resources:
      limits:
        memory: 1Gi
    output:
      to:
        kind: ImageStreamTag
        name: ${APPLICATION_NAME}:latest
    source:
      git:
        uri: ${GIT_URI}
      type: Git
    strategy:
      type: Source
      sourceStrategy:
        env:
        - name: APP_FILE
          value: 'app.py'
        - name: GIT_SSL_NO_VERIFY
          value: 'true'
        forcePull: true
        from:
          kind: DockerImage
          name: 'docker.io/centos/python-36-centos7:latest'
    triggers:
    - imageChange: {}
      type: ImageChange
    - type: ConfigChange
    - gitlab:
        secretReference:
          name: "scrape-prometheus-githook"
      type: "GitLab"

- apiVersion: batch/v2alpha1
  kind: CronJob
  metadata:
    labels:
      run: "${APPLICATION_NAME}"
      app: "${APPLICATION_NAME}"
    name: "${APPLICATION_NAME}"
  spec:
    concurrencyPolicy: Forbid
    suspend: true
    failedJobsHistoryLimit: 1
    successfulJobsHistoryLimit: 3
    jobTemplate:
      metadata:
        creationTimestamp: null
      spec:
        template:
          metadata:
            creationTimestamp: null
            labels:
              run: "${APPLICATION_NAME}"
          spec:
            containers:
            - image: ${APPLICATION_NAME}:latest
              name: "${APPLICATION_NAME}"
              imagePullPolicy: Always
              resources: {}
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: File
              concurrencyPolicy: Forbid
              resources:
                limits:
                  cpu: '1'
                  memory: 16Gi
                requests:
                  cpu: '1'
                  memory: 2Gi
              env:
              - name: PROM_BACKUP_ALL
                value: "true"
              - name: BEARER_TOKEN
                value: "${BEARER_TOKEN}"
              - name: URL
                value: "${URL}"
              - name: BOTO_ACCESS_KEY
                value: "${BOTO_ACCESS_KEY}"
              - name: BOTO_SECRET_KEY
                value: "${BOTO_SECRET_KEY}"
              - name: BOTO_OBJECT_STORE
                value: "${BOTO_OBJECT_STORE}"
              - name: BOTO_STORE_ENDPOINT
                value: "${BOTO_STORE_ENDPOINT}"
            dnsPolicy: ClusterFirst
            restartPolicy: Never
            schedulerName: default-scheduler
            securityContext: {}
            terminationGracePeriodSeconds: 30
    schedule: "${SCHEDULE}"
    suspend: false

parameters:
- description: The name for job
  from: 'scrape-prometheus-[a-z0-9]{4}'
  generate: expression
  name: APPLICATION_NAME
  required: true
- name: GIT_URI
  value: https://gitlab.cee.redhat.com/asanmukh/scrape_prometheus.git
  required: true
- name: URL
  description: URL of prometheus server
  required: true
- name: BEARER_TOKEN
  description: Bearer Token for accessing prometheus
  required: true
- name: SCHEDULE
  description: Schedule for the cronjob
  value: '0 1 * * *'
- name: BOTO_ACCESS_KEY
  description: Access key to connect to CEPH endpoint storage (or any similar S3 type storage)
  required: true
- name: BOTO_SECRET_KEY
  description: Secret key to connect to CEPH endpoint storage (or any similar S3 type storage)
  required: true
- name: BOTO_OBJECT_STORE
  description: Bucket Name on CEPH  (or any similar S3 type storage)
  required: true
- name: BOTO_STORE_ENDPOINT
  description: The URL to connect to the CEPH storage (or any similar S3 type storage)
  required: true
